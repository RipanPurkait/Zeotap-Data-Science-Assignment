{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1KzdmEAmu0XjCTO4nHz-e57leUhWJfHd8","authorship_tag":"ABX9TyNxwjS0B4tra+MiLzfTgH6o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","from datetime import datetime\n","import numpy as np\n","from sklearn.impute import SimpleImputer\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics.pairwise import cosine_similarity\n","import json\n","\n","# Load data\n","customers = pd.read_csv('/content/drive/MyDrive/Zeotap/Customers.csv')\n","transactions = pd.read_csv('/content/drive/MyDrive/Zeotap/Transactions.csv')\n","\n","# Merge datasets\n","data = pd.merge(customers, transactions, on='CustomerID', how='left')\n","\n","# Convert dates to datetime, handling NA values\n","data['SignupDate'] = pd.to_datetime(data['SignupDate'], errors='coerce')\n","data['TransactionDate'] = pd.to_datetime(data['TransactionDate'], errors='coerce')\n","\n","# Handle missing values for date calculations\n","current_date = datetime.now()  # or any reference date\n","\n","data['CustomerAge'] = (current_date - data['SignupDate']).dt.days\n","data['Recency'] = (current_date - data['TransactionDate']).dt.days\n","\n","# Aggregate data per customer, handling NA values\n","agg_data = data.groupby('CustomerID').agg({\n","    'ProductID': lambda x: list(x.dropna()),  # List of products bought, remove NA\n","    'Recency': lambda x: x.min() if not x.dropna().empty else np.nan,  # Last transaction\n","    'TransactionDate': 'count',  # Frequency of transactions\n","    'Region': 'first',  # Assuming region doesn't change\n","    'CustomerAge': 'first'\n","}).reset_index().rename(columns={'TransactionDate': 'Frequency'})\n","\n","# Handle missing values in numeric columns\n","numeric_features = ['CustomerAge', 'Recency', 'Frequency']\n","imputer = SimpleImputer(strategy='mean')  # or median or constant\n","agg_data[numeric_features] = imputer.fit_transform(agg_data[numeric_features])\n","\n","# Vectorize product IDs\n","agg_data['ProductList'] = agg_data['ProductID'].apply(lambda x: ' '.join(map(str, x)) if isinstance(x, list) else '')\n","vectorizer = CountVectorizer()\n","product_matrix = vectorizer.fit_transform(agg_data['ProductList'])\n","\n","# Scale numerical features\n","scaler = StandardScaler()\n","scaled_features = scaler.fit_transform(agg_data[numeric_features])\n","\n","# Combine with product features (sparse matrix)\n","from scipy.sparse import hstack\n","features = hstack([scaled_features, product_matrix])\n","\n","# Compute similarity matrix\n","similarity_matrix = cosine_similarity(features)\n","\n","def get_lookalikes(customer_id, similarity_matrix, n=2):\n","    # Index of the customer in the matrix\n","    idx = agg_data.index[agg_data['CustomerID'] == customer_id].tolist()[0]\n","    # Get similarity scores for this customer with all others\n","    sim_scores = list(enumerate(similarity_matrix[idx]))\n","    # Sort by similarity score, excluding self\n","    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:n+1]  # Exclude self\n","    # Map back to customer IDs\n","    lookalikes = [(agg_data.iloc[i]['CustomerID'], score) for i, score in sim_scores if not np.isnan(score)]\n","    return lookalikes\n","\n","# Generate lookalikes for the first 20 customers\n","lookalike_dict = {}\n","for customer_id in agg_data['CustomerID'].unique()[:20]:\n","    lookalike_dict[customer_id] = get_lookalikes(customer_id, similarity_matrix)\n","\n","# Save results\n","with open('Lookalike.csv', 'w') as f:\n","    for key, value in lookalike_dict.items():\n","        f.write(f\"{key},{json.dumps(value)}\\n\")"],"metadata":{"id":"UtLs3W8aUzG9","executionInfo":{"status":"ok","timestamp":1737996458028,"user_tz":-330,"elapsed":712,"user":{"displayName":"RIPAN PURKAIT","userId":"00658727198455329811"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"P7zEheYmUmND"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kkinbwhRUmQU"},"execution_count":null,"outputs":[]}]}